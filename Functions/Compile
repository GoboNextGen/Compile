#!/bin/bash

Import File
Import RecipeTools

##################################################
# Setting up variables
##################################################

if [ -z "$compileRecipeDir" ]
then
   compileRecipeDir="${compileRecipesDir}"
fi

compileSupportedArchitectures=("i686" "x86_64" "ppc" "arm" "sh4")

##################################################
# API functions
##################################################

function Check_Dir_Variable() {
   var="$1"
   eval [ "\"\${${var}}\"" ] || Die "Variable \\\$$var is not set. Please update your Compile.conf."
   eval Assert_Dir "\"\${${var}}\""
}

# Return status:
# 0 - Files were verified and are okay.
# 1 - Files are corrupted
# 2 - Files look incomplete or cannot be verified
# 3 - Files are missing.
function Verify_Files() {
   local myfiles=($1)
   local sizes=($2)
   local sums=($3)
   local use_sha=($4)
   if [ $use_sha == 1 ]
   then Get_Sum="Get_SHA"
   else Get_Sum="Get_MD5"
   fi
   for i in $(seq 0 $[${#myfiles[@]}-1])
   do
      file="$compileArchivesDir/${myfiles[i]}"
      file_size="${sizes[i]}"
      file_sum="${sums[i]}"
      if [ -f "$file" ]
      then
         size=$(Get_Size "$file")
         sum=$(${Get_Sum} "$file")
         if [ -n "$file_size" ] && [ "$file_size" != "$size" ]
         then
            Log_Terse "Warning: $file is either not complete or corrupted."
            return 2
         elif [ -n "$file_size" ]
         then
            if [ -z "$file_sum" ]
            then
               Log_Normal "Warning: no MD5/SHA checksum."
               Log_Normal "Assuming $file is complete based only on size."
               return 0
            elif [ "$file_sum" = "$sum" ]
            then
               Log_Verbose "$file is complete and matches MD5/SHA checksum."
            else
               Log_Error "According to MD5/SHA checksum, $file is corrupted."
               return 1
            fi
         else
            if [ -z "$file_sum" ]
            then
               Log_Terse "Warning: no file size or MD5/SHA checksum. $file cannot be verified"
               return 2
            elif [ "$file_sum" = "$sum" ]
            then
               Log_Normal "Warning: file size could not be verified but $file matches MD5/SHA checksum."
               return 2
            else
               Log_Error "According to MD5/SHA checksum, $file is corrupted."
               return 1
            fi
         fi
      else
         return 3
      fi
   done
   return 0
}

function get_url_basename() {
   local url="$1"
   if [ "$cached_bname_input" = "$url" ]
   then
      echo "$cached_bname_output"
      return
   fi
   bname=`basename "$url" .tar.gz`
   bname=`basename "$bname" .tar.bz2`
   bname=`basename "$bname" .tar.xz`
   bname=`basename "$bname" .tgz`
   bname=`basename "$bname" .tbz2`
   bname=`basename "$bname" .zip`
   bname=`basename "$bname" .tar.lzma`
   cached_bname_input="$url"
   cached_bname_output="$bname"
   echo "$bname"
}

function Package_Name_From_Url() {
   local url="$1"
   local bname=$(get_url_basename "$url")
   local packagename=`echo "$bname" | sed 's/-[[:digit:]].*//g'`
   local deduced=`DeduceName "README" "$packagename"`
   [ "$deduced" ] && packagename=$deduced
   echo "$packagename"
}

function Version_Number_From_Url() {
   local url="$1"
   local bname=$(get_url_basename "$url")
   local versionnumber=`echo "$bname" | sed 's/.*-\([[:digit:]].*\)/\1/;s/\///g;'`
   echo "$versionnumber"
}

Find_Recipe() {
   app="$1"
   appversion="$2"
   tarballurl="$3"
   
   if Has_Substring "$appversion" ":/"
   then
      tarballurl="$2"
      appversion=$(Version_Number_From_Url "$tarballurl")
   fi
   
   Find_Recipe_Program_And_Version pull "$app" "$appversion"
   err=$?
   if [ "$err" = 0 ]
   then
      echo "$recipedir/Recipe"
      return 0
   fi

   Find_Recipe_Program_And_Version no "$app" ""
   err=$?
   if [ "$err" = 0 ] && [ "$appversion" ]
   then
      Log_Terse "Could not find recipe for $app $appversion."
      { Boolean "batch" || Ask_Continue "Attempt to create recipe for version $appversion?"
      } && NewVersion $app $appversion "${tarballurl}"
      Find_Recipe_Program_And_Version no "$app" "" && {
         echo "$recipedir/Recipe"
         return 0
      }
      return 1
   fi

   Log_Error "Could not find a recipe for $app"
   ls $compileRecipesDir | cut -d' ' -f2 | uniq | Corrections --log-name Compile --stdin "$app">&2
   if [ "$tarballurl" ]
   then
      Log_Normal "Will attempt to create one based on URL '$tarballurl'..."
      if MakeRecipe --batch "$app" "$appversion" "$tarballurl"
      then
         Log_Normal "Will attempt to use newly created recipe..."
         Find_Recipe_Program_And_Version no "$app" "$appversion" && {
            echo "$recipedir/Recipe"
            return 0
         }
      fi
   fi

   return 1
}

Available_BuildTypes() {
   sed 's,.*Functions/BuildType_\(.*\)$,\1,' < <(ls "${scriptPath}/../Functions"/BuildType_*)
}

##################################################
# Helper functions
##################################################

function is_function_set() {
   [ "`type -t $1`" = "function" ]
}

### Future Scripts functions... ###

function Run_Hook() {
   hook="$1"
   ret=0
   if is_function_set "$hook"
   then
      real_run_hook "$hook" || ret=$?
   fi
   for flag in "${useflags[@]}"
   do
      if is_function_set "using_${flag}_${hook}"
      then
         real_run_hook "using_${flag}_${hook}" || ret=$?
      fi
   done
   return $ret
}

function real_run_hook() {
   Parameters "$@" hookname
   hookscript=./${hookname}.sh
   echo "#!/bin/bash" > ${hookscript}
   echo "source ScriptFunctions" >> ${hookscript}
   echo "Import GoboLinux" >> ${hookscript}
   echo "Import OptionParser" >> ${hookscript}
   echo "Import Log" >> ${hookscript}
   for v in ${variablestoexport[@]}
   do
      echo "export ${v}=\"$(eval echo \$${v})\"" >> ${hookscript}
   done
   echo "source $goboSettings/Compile/Compile.conf" >> ${hookscript}
   echo "source ${recipe}" >> ${hookscript}
   [ -e "$archrecipe" ] && echo "source ${archrecipe}" >> ${hookscript}
   echo "$hookname" >> ${hookscript}
   chmod a+x "${hookscript}"
   "${hookscript}"
   rtn=$?
   rm -f ${hookscript}
   return ${rtn}
}

function Add_Use_Flags_Options_To_Array() {
   array=$1
   for flag in "${useflags[@]}"
   do
      if [ -n "`eval echo '$'with_$flag`" ]
      then
         eval $(Combine_Arrays $array $array with_$flag)
      fi
   done
}

#
# do_fetch
#    Fetches sources
#  $1: [0|1] -> 1 to ignore certificates when downloading sources, 0 otherwise
# returns:
#  0 <- success
#  1 <- Error fetching sources
#  2 <- Downloaded files were corrupted
#  3 <- fetch cancelled by user
function do_fetch() {
   ignore_certificate=$1
   fetch_extra_params=""
   [[ $ignore_certificate -eq 1 ]] && fetch_extra_params="--no-check-certificate"

   savedir="--save-to $(echo ${sourcedir}|sed s/"\(.*\)\/${save_directory}.*"/"\1"/) --save-directory ${save_directory}"
   if is_scm_recipe
   then
      # If sources were already fetched, do not patch again
      if [ -d "${sourcedir}" ]
      then
         if [ -z "$(echo "${version}" | grep -qiE "svn|cvs|git|bzr|hg")" ]
         then
            if Boolean "lazy"
            then REPLY=u
            elif Boolean "no-web"
            then REPLY=u
            elif Boolean "batch"
            then REPLY=r
            else
               Log_Question "Directory '${basedir}' already exists."
               Ask_Option "What to do? [R]emove and check out/[B]ackup and check out/[U]se it/[C]ancel."
            fi
            case $REPLY in
            [Rr]) rm -rf "${basedir}" 2>/dev/null ;;
            [Bb]) mv "${basedir}" "${basedir}.backup"; chown -R `whoami` "${basedir}.backup" ;;
            [Uu]) nofetch=yes; skippatching=yes ;;
            [Cc]) Log_Error "Fetch cancelled by user."; return 3 ;;
            esac # esac is ridiculous.
         else skippatching=yes
         fi
      else
         if Boolean "no-web"
         then
            Log_Error "Files are not available and --no-web was used."
            return 1
         fi
      fi
      [ "$nofetch" = "yes" ] || FetchArchive -P "$appname" -V "$versionnumber" $verbose $batch $savedir "$recipe" "$archrecipe" $fetch_extra_params || {
         Log_Error "Error fetching snapshot from repository."
         return 1
      }
   else
      if ! Boolean "no-web"
      then
         FetchArchive -P "$appname" -V "$versionnumber" $verbose $batch "$recipe" "$archrecipe" $fetch_extra_params || {
            Log_Error "Error fetching archive(s)."
            return 1
         }
      else
         # Use sha checksum if available
         if [ -n "${file_shas}" ];
         then Verify_Files "${files[*]}" "${file_sizes[*]}" "${file_shas[*]}" 1
         else Verify_Files "${files[*]}" "${file_sizes[*]}" "${file_md5s[*]}" 0
         fi
         result=$?
         case $result in
         1) Log_Error "Files are corrupted. Exiting."; return 2 ;;
         2) Boolean "batch" || Ask_Continue "Continue anyway?" || return 3 ;;
         3) Log_Error "Files are not available. Exiting."; return 1 ;;
         esac
      fi
   fi
}

function do_unpack() {
   pfiles=`
      for i in "${files[@]}"
      do ls "$compileArchivesDir"/"$i"
      done
   `
   String_To_Array files "$pfiles"

   if [ "$uncompress" = "no" ]
   then
      [ "$basedir" ] || basedir=$appname
      [ "$unpack_files" ] || unpack_files=files_in_root
   fi

   unpack=yes
   if [ -d "${basedirs[0]}" ]
   then
      if Boolean "lazy"
      then REPLY=u
      elif Boolean "batch"
      then REPLY=r
      else
         Log_Question "Directory '${basedir}' already exists."
         Ask_Option "What to do? [R]emove and reunpack/[B]ackup and reunpack/[U]se it/[C]ancel."
      fi
      case $REPLY in
      [Rr]) rm -rf "${basedir}" 2>/dev/null || rm -rf "${basedirs[0]}" ;;
      [Bb]) mv "${basedir}" "${basedir}.backup"; chown -R `whoami` "${basedir}.backup" ;;
      [Uu]) unpack=no; skippatching="yes" ;;
      [Cc]) exit 0 ;;
      esac # esac is ridiculous.
   fi

   tempdir="$appname.$versionnumber.Compile.temp"
   [ "$unpack" = "yes" ] && \
   for ((i=0; i < ${#files[@]}; i++))
   do
      drop=.
      skipdir=
      if [ "$unpack_files" = "files_in_root" ]
      then
         drop="${basedirs[0]}"
      elif [ "$unpack_files" = "inside_first" ]
      then
         if [ $i -gt 0 ]
         then
            drop="${basedirs[0]}"
         fi
      elif [ "$unpack_files" = "contents_inside_first" ]
      then
         drop="${basedirs[0]}"
         skipdir="${basedirs[i]}"
      elif [ "$unpack_files" = "dirs" ]
      then
         if [ "$i" -eq 0 ]
         then
            drop=.
         else
            drop="${basedirs[i]}"
            if [ ! "$keep_existing_target" ] && echo "$drop" | Quiet grep "$target"
            then keep_existing_target=yes
            fi
         fi
      fi

      if [ "$unpack_files" -o $i -eq 0 ]; then
         Quiet pushd "$compileSourcesDir"
         [ -d "${tempdir}" ] && rm -rf "${tempdir}"
         mkdir "${tempdir}"
      fi

      Log_Normal "Unpacking file ${files[i]}..."
      if [ "$uncompress" = "no" ]
      then Verbose cp -v "${files[i]}" "${tempdir}" || Die "Could not copy '${files[i]}'."
      else Verbose Unpack_Archive "${files[i]}" "${tempdir}" || Die "Could not unpack '${files[i]}'."
      fi

      if [ "$unpack_files" -o $i -eq $(( ${#files[@]} - 1 )) ]; then
         mkdir -p "$drop"
         $chown -R --reference="${tempdir}" "${tempdir}"
         Quiet mv "${tempdir}"/"$skipdir"/* "${tempdir}"/"$skipdir"/.[A-z]* "$drop"
         rm -rf "${tempdir}"
         Quiet popd
      fi
   done
   if [ "$unpack" = "no" ]
   then skippatching=yes
   fi
}

function do_patch() {
   pushd "${basedir}" &> /dev/null

   # Store state of nullglob and then set it explicitly
   shopt nullglob &>/dev/null && nullglob=1 || nullglob=0
   shopt -s nullglob
   
   for i in "$recipedir/"*.patch "$archsubdir/"*.patch
   do
      Log_Normal "Applying patch $i..."
      patch -Np1 -i "$i" || Die "Failed on patch $i"
   done
   # restore state of nullglob
   [ "1" = "$nullglob" ] || shopt -u nullglob

   while read patch
   do
      Log_Verbose "Applying patch generated from ${patch}..."
      patch -Np1 < <(export_marked; ApplyVariables -i Compile "${patch}") || Die "Failed on patch generated from $patch"
   done < <(find "$recipedir" -name "*.patch.in" | sort)

   popd &> /dev/null
}

function do_configuration() {
   ! is_function_set ${recipe_type}_do_configuration || ${recipe_type}_do_configuration
}

function do_build() {
   ! is_function_set ${recipe_type}_do_build || ${recipe_type}_do_build
}

function do_install() {
   ! is_function_set ${recipe_type}_do_install || ${recipe_type}_do_install "${1}" "${2}"
}

function do_strip() {
   Log_Normal "Stripping executables..."
   [ "$STRIP" ] || STRIP=strip
   local d
   for d in bin sbin
   do
      Quiet pushd "$target/$d"
      for i in *
      do
         if file "$i" | grep -q -i "ELF .* executable"
         then Verbose $STRIP "$i"
         fi
      done
      Quiet popd
   done
}

function do_symlink() {
   local forcelink=no
   [ "force" == "$(Entry symlink)" ] && forcelink=yes
   while true
   do
      case "$1" in
      --force-link) forcelink=yes ; shift ;;
      *) break ;;
      esac # it still is.
   done

   if [ "$(Entry symlink)" == "no" ] && [ "$forcelink" != "yes" ]
   then
      Clean_Program_Tree "${goboPrograms}/$1/$2" || wrap_fail "Failed cleaning up tree."
   else
      unset updateoptions
      Boolean "batch" && updateoptions="--auto"
      if [ ! "$compileMetaRecipe" ] || [ "$compileMetaRecipe" -a "$update_each_settings" = "yes" ]
      then
         if ! Boolean "no-updatesettings"
         then UpdateSettings $updateoptions "$1" "$2" || wrap_fail "Failed updating settings."
         fi
      fi
      [ "$needs_safe_linking" = "yes" ] && safeopts="--libraries safe --executables safe"
      [ "$forcelink" = "yes" ] && forcesymlinking="--force"
      [ "$batch" ] && unmanaged_opts="--unmanaged install"
      Boolean "no-unmanaged" && unmanaged_opts="--unmanaged skip"
      SymlinkProgram $safeopts $unmanaged_opts $forcesymlinking ${symlink_options:+"${symlink_options[@]}"} "$1" "$2" || wrap_fail "Linking step failed."
   fi
}

function install_extras() {
   if [ -d "$reciperesources" ]
   then
      cp -Rf "$reciperesources" "$installprefix" || wrap_fail "Failed copying files."
   fi
   if [ -d "$archreciperesources" ]
   then
      cp -Rf "$archreciperesources" "$installprefix" || wrap_fail "Failed copying files."
   fi
   if [ "$revision" ]
   then
      echo "$revision" | tee "$installprefix/Resources/Revision" >/dev/null || wrap_fail "Failed installing file."
   fi

   if [ "$app" = "$appname" ]
   then
      CheckDependencies --mode=convert --file $recipedir/Resources/Dependencies | tee "$installprefix/Resources/Dependencies" >/dev/null
   fi

   if [ "$app" ]
   then name=$app
   else name=$appname
   fi
   unixname=`echo $name | tr "[:upper:]" "[:lower:]"`-$version
   docdir="$installprefix/doc/$unixname"

   for d in "${dirs[@]}"
   do
      Quiet pushd "$d" && {
         for i in COPYING LICENSE README* NEWS AUTHORS BUGS TODO COPYRIGHT ${docs:+"${docs[@]}"}
         do
            if [ -e "$d/$i" ]
            then
               mkdir -p "$docdir" || return 1
               cp -a "$d/$i" "$docdir" || return 1
            fi
         done
         Quiet popd
      }
   done

   if [ "${unmanaged_files[*]}" ] 
   then
      rm -f -- $target/Resources/UnmanagedFiles
      for file in "${unmanaged_files[@]}"
      do echo $file | sed 's,'"$goboPrefix"'/,/,' | tee -a "$target/Resources/UnmanagedFiles" >/dev/null
      done
      if echo "${unmanaged_files[@]}" | grep -q "$goboModules" && [ "$app" != "Linux" ]
      then
         mkdir -p "$target/$(basename $goboShared)/Compile/Recompile/Linux"
         touch "$target/$(basename $goboShared)/Compile/Recompile/Linux/$app"
      fi
   fi
   return 0
}

function assert_requirements() {
   Log_Normal "Asserting that requirements are met..."
   Process_Requirements_File "$recipedir"
}

function mark_export() {
   export variablestoexport="$variablestoexport $*"
}

function export_marked() {
   for var in $variablestoexport
   do
      export $var
   done
}

function Get_Dependency_Variables() {
   dependencies_file="$1"
   if [ -f "$dependencies_file" ]
   then
      while read dep
      do
         depname="$(echo $dep | cut -d ' ' -f1)"
         depverrev="$(echo $dep | cut -d ' ' -f2)"
         depver="$(echo $depverrev | cut -d '-' -f1)"
         depdir="$(echo $dep | cut -d' ' -f4)"
         lowercasename=`echo $depname | tr '[:upper:]-+:' '[:lower:]___'`
         dep_settings_path="$(Get_Dir runtimeSettings ${depname} ${depver})"
         dep_variable_path="$(Get_Dir runtimeVariable ${depname} ${depver})"
         eval $lowercasename'_path="'"$depdir"'"'
         eval $lowercasename'_settings_path="'"$dep_settings_path"'"'
         eval $lowercasename'_variable_path="'"$dep_variable_path"'"'
         mark_export ${lowercasename}_path ${lowercasename}_settings_path ${lowercasename}_variable_path
      done < <(CheckDependencies --no-recursive --types=installed --quiet-progress --mode=all --file "$dependencies_file")
   fi
}

function Fix_Legacy_Recipe_Types() {
   # Backwards compability fix
   [ "$is_compileprogram" = "yes" ] && recipe_type="configure"
   [ "$is_makefile" = "yes" ] && recipe_type="makefile"
   [ "$is_python" = "yes" ] && recipe_type="python"
   [ "$is_xmkmf" = "yes" ] && recipe_type="xmkmf"
   [ "$is_meta" = "yes" ] && recipe_type="meta"
   [ "$is_meson" = "yes" ] && recipe_type="meson"
   [ "$is_scons" = "yes" ] && recipe_type="scons"
   [ "$is_manifest" = "yes" ] && recipe_type="manifest"
}
